
In \Cref{fig:task_deltas}, we analyze task-wise performance degradation across six efficient inference techniques, revealing striking differences in task vulnerability. Quantization methods (NF4 and Int8) demonstrate minimal and uniform degradation across all task categories, averaging -0.71\% ± 1.17\%, with no task exceeding 3.50\% degradation. In stark contrast, token eviction methods (SnapKV, PyramidKV, StreamingLLM) show severe task-dependent performance degradation averaging -15.29\% ± 16.32\%, with catastrophic failures on memory-intensive tasks. Specifically, Recall tasks suffer -56.24\% ± 8.38\% degradation under token eviction versus -0.93\% ± 0.64\% under quantization (gap: 55.31 percentage points), while Re-rank tasks degrade by -27.78\% ± 9.23\% versus -0.81\% ± 1.02\% (gap: 26.97 percentage points). NIAH tasks similarly show -21.83\% ± 21.90\% degradation under eviction versus 0.12\% ± 0.25\% under quantization. Task type analysis reveals systematic patterns: memory retrieval tasks (NIAH, Recall) average -39.03\% degradation under eviction, information retrieval tasks (RAG, Re-rank) average -17.51\%, while reasoning tasks (Summ, Pseudo, ICL) demonstrate relative resilience at -1.95\%. DuoAttention shows moderate task-dependent behavior with 0.50\% degradation on Recall and -0.25\% on Re-rank, substantially outperforming token eviction methods but exhibiting more task variance than quantization. These findings demonstrate that token eviction methods fundamentally compromise tasks requiring precise retrieval of cached information, while quantization preserves performance uniformly across task types, and reasoning tasks requiring semantic understanding remain relatively robust regardless of efficiency technique.
